[{"title":"CNN训练模型实现验证码自动识别","path":"/2025/03/28/CNN训练模型实现验证码自动识别/","content":"注：本文中所有代码均是问AI实现（因为我是一点不会写💀）题目：2000个验证码，正确率95%即可通过 去搜了一下常见的本地ocr平台，尝试搭建ddddocr https://github.com/sml2h3/ddddocrhttps://github.com/sml2h3/ddddocr 尝试了一下直接使用自带的模型发现效果非常不理想 所以先尝试对图片进行处理（滤波）（这里我要提一位老师了–赖志辉老师，他上个学期给我们分配任务去做pre，我负责的就是滤波器，这才知道世界上有滤波器这种东西，才能把这道题做出来） 先创一个虚拟环境吧，这边用的是python3.9（版本太高貌似不行） 123&quot;C:\\Users\\xiaoy\\AppData\\Local\\Programs\\Python\\Python39\\python.exe&quot; -m venv venv_py39venv_py39\\Scripts\\activate 先去掉蓝色混淆线条，并灰度处理 去除蓝色混淆线条123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from PIL import Imageimport numpy as npimport colorsysdef rgb_to_hsv(rgb): return colorsys.rgb_to_hsv(rgb[0]/255.0, rgb[1]/255.0, rgb[2]/255.0)def remove_specific_rgba(img, target_rgba): &quot;&quot;&quot;删除特定RGBA颜色的像素（设置为透明）&quot;&quot;&quot; img = img.convert(&quot;RGBA&quot;) data = np.array(img) r, g, b, a = data[:,:,0], data[:,:,1], data[:,:,2], data[:,:,3] mask = (r == target_rgba[0]) &amp; (g == target_rgba[1]) &amp; (b == target_rgba[2]) &amp; (a == target_rgba[3]) data[mask] = [0, 0, 0, 0] # 设置为完全透明 return Image.fromarray(data)# 参数设置target_blue = (64, 56, 247)hue_range = (0.58, 0.72)sat_threshold = 0.3val_threshold = 0.5remove_color = (254, 224, 222, 255) # 新增要删除的RGBA颜色# 读取图片img = Image.open(r&quot;F:\\ctf\\ocr proj\\ddddocr-full\\generate_captcha.png&quot;).convert(&quot;RGB&quot;)pixels = np.array(img)# 原始颜色过滤流程hsv_pixels = np.array([[[colorsys.rgb_to_hsv(p[0]/255., p[1]/255., p[2]/255.)] for p in row] for row in pixels])hsv_pixels = np.squeeze(hsv_pixels)h_mask = (hsv_pixels[:,:,0] &gt;= hue_range[0]) &amp; (hsv_pixels[:,:,0] &lt;= hue_range[1])s_mask = hsv_pixels[:,:,1] &gt;= sat_thresholdv_mask = hsv_pixels[:,:,2] &gt;= val_thresholdcombined_mask = h_mask &amp; s_mask &amp; v_maskpixels[combined_mask] = [255, 255, 255]color_img = Image.fromarray(pixels)# 新增RGBA删除模块color_img = remove_specific_rgba(color_img, remove_color)# 保存彩色结果（带透明通道）color_img.save(&quot;filtered_image_hsv.png&quot;)print(&quot;改进后的过滤完成，彩色结果已保存为 filtered_image_hsv.png&quot;)# 转换为灰度（自动忽略透明像素）gray_img = color_img.convert(&#x27;L&#x27;)gray_img.save(&quot;filtered_image_gray.png&quot;)print(&quot;灰度结果已保存为 filtered_image_gray.png&quot;) 原图: 效果如下: 清晰多了，这时候去识别还是不理想，就又加了个锐化滤波器效果如下: 还是识别错误 于是我尝试使用最后的方法生成训练集，本地训练，用本地训练的模型来识别用到了ddddocr_train https://github.com/sml2h3/dddd_trainerhttps://github.com/sml2h3/dddd_trainer 安装cuda和pytorch这里不再赘述（反正我是第一次安装并用显卡训练，过程可以说是一波三折，有好多报错，不过好在有AI帮我把问题都解决了） ddddocr_train的github有详细使用方法 这道题目给了php源码，所以先生成几万张标注好的验证码 用AI修改题目中的源码，用户每次触发生成多张验证码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?php// 设置保存路径$savePath = &#x27;D:/phpstudy_pro/WWW/IMAGE/captcha&#x27;;// 创建目录（如果不存在）if (!is_dir($savePath)) &#123; mkdir($savePath, 0755, true);&#125;// 生成100张验证码for ($i = 0; $i &lt; 100; $i++) &#123; generateCaptcha($savePath);&#125;function generateCaptcha($savePath) &#123; // 创建图像资源 $image = imagecreate(100, 50); // 生成随机颜色 $background_color = imagecolorallocate($image, rand(220, 255), rand(220, 255), rand(220, 255)); $text_color1 = imagecolorallocate($image, rand(0, 100), rand(0, 100), rand(0, 100)); $text_color2 = imagecolorallocate($image, rand(0, 100), rand(0, 100), rand(0, 100)); $line_color = imagecolorallocate($image, 0, 0, 255); // 填充背景 imagefill($image, 0, 0, $background_color); // 生成随机验证码 $chars = &quot;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;; $code = substr(str_shuffle($chars), 0, 4); // 绘制验证码文本 $font_size = 5; for ($i = 0; $i &lt; strlen($code); $i++) &#123; $color = ($i % 2 == 0) ? $text_color1 : $text_color2; $x = 10 + ($i * 15) + mt_rand(-5, 5); $y = mt_rand(10, 30); imagestring($image, $font_size, $x, $y, $code[$i], $color); &#125; // 添加干扰线 for ($i = 0; $i &lt; 5; $i++) &#123; imageline($image, mt_rand(0, 100), mt_rand(0, 50), mt_rand(0, 100), mt_rand(0, 50), $line_color ); &#125; // 生成唯一文件名（验证码内容+微秒时间戳） $timestamp = str_replace(&#x27;.&#x27;, &#x27;_&#x27;, microtime(true)); $filename = &quot;&#123;$code&#125;_&#123;$timestamp&#125;.png&quot;; $filePath = $savePath . &#x27;/&#x27; . $filename; // 保存图像 imagepng($image, $filePath); imagedestroy($image);&#125;echo &quot;已生成100张验证码到目录：&#123;$savePath&#125;&quot;;?&gt; 这里用时间戳不对，训练不出来，后来又用python脚本把标注好的后面的时间戳全部换成ddddocr要求的32位随机hex值 批量重命名成规范格式1234567891011121314151617181920212223242526272829303132333435363738394041424344import osimport shutilimport secretsdef rename_and_copy_images(): # 定义源目录和目标目录 source_dir = r&#x27;D:\\phpstudy_pro\\WWW\\IMAGE\\captcha_sharped&#x27; dest_dir = r&#x27;D:\\phpstudy_pro\\WWW\\IMAGE ewcaptcha&#x27; # 支持的图片扩展名列表 image_extensions = (&#x27;.png&#x27;, &#x27;.jpg&#x27;, &#x27;.jpeg&#x27;, &#x27;.gif&#x27;, &#x27;.bmp&#x27;) # 创建目标目录（如果不存在） os.makedirs(dest_dir, exist_ok=True) # 遍历源目录中的所有文件 for filename in os.listdir(source_dir): # 检查是否为图片文件 if filename.lower().endswith(image_extensions): # 分离文件名和扩展名 name_part, ext = os.path.splitext(filename) # 跳过不足5个字符的文件名 if len(name_part) &lt; 5: print(f&quot;警告：跳过文件 &#x27;&#123;filename&#125;&#x27;，文件名长度不足5个字符&quot;) continue # 构建新文件名 prefix = name_part[:5] random_hex = secrets.token_hex(16) # 生成32位随机hex new_filename = f&quot;&#123;prefix&#125;&#123;random_hex&#125;&#123;ext&#125;&quot; # 构建完整文件路径 src_path = os.path.join(source_dir, filename) dst_path = os.path.join(dest_dir, new_filename) # 复制文件到目标目录 shutil.copy2(src_path, dst_path) print(f&quot;已处理：&#123;filename&#125; -&gt; &#123;new_filename&#125;&quot;)if __name__ == &quot;__main__&quot;: rename_and_copy_images() print(&quot;所有图片处理完成！&quot;) 接着就是两个批量滤波（把原来的单张图片滤波代码丢进AI，给出原始图片路径和目标文件夹，让AI生成，如果有报错就把错误信息投喂给AI，根据AI生成的解决方案逐步排查） 去除混淆蓝色线条123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566from PIL import Imageimport numpy as npimport colorsysimport osimport globdef rgb_to_hsv(rgb): return colorsys.rgb_to_hsv(rgb[0]/255.0, rgb[1]/255.0, rgb[2]/255.0)def remove_specific_rgba(img, target_rgba): &quot;&quot;&quot;删除特定RGBA颜色的像素（设置为透明）&quot;&quot;&quot; img = img.convert(&quot;RGBA&quot;) data = np.array(img) r, g, b, a = data[:,:,0], data[:,:,1], data[:,:,2], data[:,:,3] mask = (r == target_rgba[0]) &amp; (g == target_rgba[1]) &amp; (b == target_rgba[2]) &amp; (a == target_rgba[3]) data[mask] = [0, 0, 0, 0] return Image.fromarray(data)# 参数设置target_blue = (64, 56, 247)hue_range = (0.58, 0.72)sat_threshold = 0.3val_threshold = 0.5remove_color = (254, 224, 222, 255)# 路径设置input_dir = r&#x27;D:\\phpstudy_pro\\WWW\\IMAGE\\captcha&#x27;output_dir = r&#x27;D:\\phpstudy_pro\\WWW\\IMAGE\\captcha_filtered&#x27;# 创建输出目录os.makedirs(output_dir, exist_ok=True)# 处理所有图片for img_path in glob.glob(os.path.join(input_dir, &#x27;*&#x27;)): try: # 读取图片 img = Image.open(img_path).convert(&quot;RGB&quot;) pixels = np.array(img) # 颜色过滤 hsv_pixels = np.array([[[colorsys.rgb_to_hsv(p[0]/255., p[1]/255., p[2]/255.)] for p in row] for row in pixels]) hsv_pixels = np.squeeze(hsv_pixels) h_mask = (hsv_pixels[:,:,0] &gt;= hue_range[0]) &amp; (hsv_pixels[:,:,0] &lt;= hue_range[1]) s_mask = hsv_pixels[:,:,1] &gt;= sat_threshold v_mask = hsv_pixels[:,:,2] &gt;= val_threshold combined_mask = h_mask &amp; s_mask &amp; v_mask pixels[combined_mask] = [255, 255, 255] color_img = Image.fromarray(pixels) # RGBA删除 color_img = remove_specific_rgba(color_img, remove_color) # 转换为灰度 gray_img = color_img.convert(&#x27;L&#x27;) # 保存结果 output_path = os.path.join(output_dir, os.path.basename(img_path)) gray_img.save(output_path) print(f&quot;处理完成: &#123;os.path.basename(img_path)&#125;&quot;) except Exception as e: print(f&quot;处理失败: &#123;os.path.basename(img_path)&#125; - &#123;str(e)&#125;&quot;) 锐化处理123456789101112131415161718192021222324252627282930313233343536373839404142434445from PIL import Imageimport numpy as npimport osimport glob# 路径配置input_dir = r&#x27;D:\\phpstudy_pro\\WWW\\IMAGE\\captcha_filtered&#x27;output_dir = r&#x27;D:\\phpstudy_pro\\WWW\\IMAGE\\captcha_sharped&#x27;# 锐化卷积核（拉普拉斯增强）sharpen_kernel = np.array([ [ 0, -1, 0], [-1, 5, -1], [ 0, -1, 0]], dtype=np.float32)def sharpen_image(img_array): &quot;&quot;&quot;执行卷积锐化操作，忽略边缘像素&quot;&quot;&quot; filtered = np.zeros_like(img_array) for i in range(1, img_array.shape[0]-1): for j in range(1, img_array.shape[1]-1): filtered[i, j] = np.sum(img_array[i-1:i+2, j-1:j+2] * sharpen_kernel) return np.clip(filtered, 0, 255).astype(np.uint8)# 创建输出目录os.makedirs(output_dir, exist_ok=True)# 批量处理for img_path in glob.glob(os.path.join(input_dir, &#x27;*&#x27;)): try: # 读取文件 img = Image.open(img_path).convert(&#x27;L&#x27;) # 执行锐化 sharpened_array = sharpen_image(np.array(img, dtype=np.float32)) # 保存结果 output_path = os.path.join(output_dir, os.path.basename(img_path)) Image.fromarray(sharpened_array).save(output_path) print(f&quot;锐化成功: &#123;os.path.basename(img_path)&#125;&quot;) except Exception as e: print(f&quot;处理失败: &#123;os.path.basename(img_path)&#125; - &#123;str(e)&#125;&quot;) 最后拿到3万多张标注好的验证码 拿去训练在ddddocr_train目录下新建虚拟环境，然后 训练123python app.py create testpython app.py cache test D:\\phpstudy_pro\\WWW\\IMAGE ewcaptchapython app.py train test 让显卡去训练即可这个训练程序默认97%准确率会停止并导出onnx模型，然后把原来的识别脚本加上导入这个onnx模型即可 每1000step会进行acc检测，如图，第一次是0刚开始训练比较慢，后面会变快 在第7000step第一次出现acc不为0，耐心等待即可 . 用4060算的，跟大模型比起来，这个显存占用率非常低第8000step直接0.71875 10000step到了0.9375第14000首次到了1.0，之后在0.96到1.0之间浮动 让AI分析一下日志 看AI解读的控制台这些数据都是什么意思就行了，下面还给了优化的代码，我不想改代码训练到大约23000step，得到正确率超过97%的模型 训练数据在 F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models找到onnx模型和charsets.json先测试一下单张图片的识别情况 测试此onnx模型能否正常使用1234567891011121314151617181920import ddddocrimport numpy as np # 添加这行导入语句ocr = ddddocr.DdddOcr(det=False, ocr=False, import_onnx_path=r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\test_1.0_21_23000_2025-03-27-11-22-33.onnx&quot;, charsets_path=r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\charsets.json&quot;)# 设置字符范围为大小写英文+数字（对应参数6）ocr.set_ranges(6)# 读取图片（注意Windows路径需要转义）image_path = r&quot;F:\\ctf\\ocr proj\\ddddocr-full\\sharpened_image.png&quot;with open(image_path, &quot;rb&quot;) as f: img_bytes = f.read()# 进行识别并获取概率结果result = ocr.classification(img_bytes, probability=True)# 拼接识别结果s = &quot;&quot;.join([result[&#x27;charsets&#x27;][np.argmax(char_probs)] for char_probs in result[&#x27;probability&#x27;]])print(&quot;&quot;, s) 遇到了点问题 让AI改一下代码 拿到修改后的代码 识别123456789101112131415161718192021222324252627import ddddocrimport numpy as npocr = ddddocr.DdddOcr( det=False, ocr=False, import_onnx_path=r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\test_1.0_21_23000_2025-03-27-11-22-33.onnx&quot;, charsets_path=r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\charsets.json&quot;)ocr.set_ranges(6)image_path = r&quot;F:\\ctf\\ocr proj\\ddddocr-full\\sharpened_image.png&quot;with open(image_path, &quot;rb&quot;) as f: img_bytes = f.read()# 直接获取识别结果（推荐）result = ocr.classification(img_bytes)print(&quot;识别结果:&quot;, result)# 若确实需要处理概率输出（需要确认数据结构）# 先检查数据结构result_with_probs = ocr.classification(img_bytes, probability=True)print(&quot;数据结构:&quot;, type(result_with_probs))print(&quot;包含的键:&quot;, result_with_probs.keys())print(&quot;probability类型:&quot;, type(result_with_probs[&#x27;probability&#x27;]))print(&quot;charsets类型:&quot;, type(result_with_probs[&#x27;charsets&#x27;])) 识别成功让AI把前面的两个滤波+ocr+验证脚本合在一起 攻击123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import requestsimport ddddocrimport numpy as npfrom PIL import Imageimport colorsysfrom io import BytesIOimport os # 添加路径验证def process_image(img_content): def rgb_to_hsv(rgb): return colorsys.rgb_to_hsv(rgb[0]/255.0, rgb[1]/255.0, rgb[2]/255.0) def remove_specific_rgba(img, target_rgba): img = img.convert(&quot;RGBA&quot;) data = np.array(img) r, g, b, a = data[:,:,0], data[:,:,1], data[:,:,2], data[:,:,3] mask = (r == target_rgba[0]) &amp; (g == target_rgba[1]) &amp; (b == target_rgba[2]) &amp; (a == target_rgba[3]) data[mask] = [0, 0, 0, 0] return Image.fromarray(data) # 参数设置 target_blue = (64, 56, 247) hue_range = (0.58, 0.72) sat_threshold = 0.3 val_threshold = 0.5 remove_color = (254, 224, 222, 255) # 从字节流读取图片 img = Image.open(BytesIO(img_content)).convert(&quot;RGB&quot;) pixels = np.array(img) # HSV过滤 hsv_pixels = np.array([[[colorsys.rgb_to_hsv(p[0]/255., p[1]/255., p[2]/255.)] for p in row] for row in pixels]).squeeze() combined_mask = (hsv_pixels[:,:,0] &gt;= hue_range[0]) &amp; (hsv_pixels[:,:,0] &lt;= hue_range[1]) &amp; \\ (hsv_pixels[:,:,1] &gt;= sat_threshold) &amp; (hsv_pixels[:,:,2] &gt;= val_threshold) pixels[combined_mask] = [255, 255, 255] color_img = remove_specific_rgba(Image.fromarray(pixels), remove_color) # 转换为灰度 gray_img = color_img.convert(&#x27;L&#x27;) # 第二阶段：锐化处理 sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32) img_array = np.array(gray_img, dtype=np.float32) filtered = np.zeros_like(img_array) for i in range(1, img_array.shape[0]-1): for j in range(1, img_array.shape[1]-1): filtered[i, j] = np.sum(img_array[i-1:i+2, j-1:j+2] * sharpen_kernel) sharpened = np.clip(filtered, 0, 255).astype(np.uint8) # 第三阶段：OCR识别（关键修改部分） try: # 路径验证（调试用） print(&quot;模型存在:&quot;, os.path.exists(r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\test_1.0_21_23000_2025-03-27-11-22-33.onnx&quot;)) print(&quot;字符集存在:&quot;, os.path.exists(r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\charsets.json&quot;)) # 初始化OCR引擎 ocr = ddddocr.DdddOcr( det=False, ocr=False, import_onnx_path=r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\test_1.0_21_23000_2025-03-27-11-22-33.onnx&quot;, charsets_path=r&quot;F:\\ctf\\ocr proj\\dddd-train\\dddd_trainer\\projects\\test\\models\\charsets.json&quot; ) ocr.set_ranges(6) # 设置字符范围 img_buffer = BytesIO() Image.fromarray(sharpened).save(img_buffer, format=&#x27;PNG&#x27;) img_bytes = img_buffer.getvalue() # 直接获取识别结果 result_text = ocr.classification(img_bytes) return result_text.replace(&quot; &quot;, &quot;&quot;).strip() except Exception as e: print(f&quot;OCR引擎异常: &#123;str(e)&#125;&quot;) return &quot;ERROR&quot;# 自动化循环部分with requests.Session() as s: base_url = &quot;http://c15f4704-4db8-4b6f-8e09-f80cd4c22d1b.ctf.szu.moe/&quot; for i in range(1, 2001): try: # 获取验证码 captcha_resp = s.get(f&quot;&#123;base_url&#125;/generate_captcha.php&quot;) if captcha_resp.status_code != 200: print(f&quot;第&#123;i&#125;次: 获取验证码失败&quot;) continue # 处理识别 captcha_text = process_image(captcha_resp.content) print(f&quot;第&#123;i&#125;次识别结果: &#123;captcha_text&#125;&quot;) # 提交验证 post_resp = s.post( f&quot;&#123;base_url&#125;/verify.php&quot;, data=&#123;&quot;captcha_input&quot;: captcha_text&#125; ) print(f&quot;第&#123;i&#125;次响应: &#123;post_resp.text.strip()&#125;&quot;) except Exception as e: print(f&quot;第&#123;i&#125;次发生异常: &#123;str(e)&#125;&quot;) continueprint(&quot;所有循环完成&quot;) 直接打即可 拿到flag"}]